{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Assignment 2 - \n",
    "## Zach Novak, Marco Bogani, Ivan Lima, Daman Sawhney and Sulaiman Karmali. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame head preview...\n",
      "     income    age  Credit_Score  dtir1  loan_amount  Status\n",
      "0   1740.0  25-34           758   45.0       116500       1\n",
      "1   4980.0  55-64           552    NaN       206500       1\n",
      "2   9480.0  35-44           834   46.0       406500       0\n",
      "3  11880.0  45-54           587   42.0       456500       0\n",
      "4  10440.0  25-34           602   39.0       696500       0\n",
      "\n",
      "Data types before processing...\n",
      " income          float64\n",
      "age              object\n",
      "Credit_Score      int64\n",
      "dtir1           float64\n",
      "loan_amount       int64\n",
      "Status            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read CSV into a DataFrame\n",
    "df = pd.read_csv(r'C:\\Users\\Setup User\\University of Central Florida\\CAP5619_GRP - General\\Script Assigments\\Script_Assign_2\\LoanData.csv')\n",
    "\n",
    "# Selecting the relevant columns\n",
    "df = df.loc[:, ['income', 'age', 'Credit_Score', 'dtir1', 'loan_amount','Status']]\n",
    "\n",
    "# df preview\n",
    "print(\"\\nDataFrame head preview...\\n\",df.head())\n",
    "\n",
    "# data types before processing\n",
    "print(\"\\nData types before processing...\\n\",df.dtypes)\n",
    "\n",
    "# Remove NA values\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# before data type can be converted to int, we need to fill in the missing values\n",
    "df['income'] = df['income'].astype(int)\n",
    "df['Credit_Score'] = df['Credit_Score'].astype(int)\n",
    "df['dtir1'] = df['dtir1'].astype(int)\n",
    "df['loan_amount'] = df['loan_amount'].astype(int)\n",
    "df['Status'] = df['Status'].astype(int)\n",
    "df['age'] = df['age'].astype(str)\n",
    "\n",
    "# Function to reformat age column\n",
    "def process_age_range(value):\n",
    "    if '-' in value:\n",
    "        age_range = value.split('-')\n",
    "        return age_range[1]\n",
    "    elif value.startswith('>'):\n",
    "        return value[1:]\n",
    "    elif value.startswith('<'):\n",
    "        return value[1:]\n",
    "    else:\n",
    "        return value\n",
    "df['age'] = df['age'].apply(process_age_range)\n",
    "\n",
    "# Set age to int data type\n",
    "df['age'] = df['age'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "df_with_nan = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Above, it can be observed that the columns chosen for this study are different data types (float64, object, int64). Code is implemented to convert all columns to an integer type as required by the Gradient Descent. For the age column, first the Process_age_function is defined to remove the value range format as seen in the DataFrame head preview per the above cell's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types post processing...\n",
      " income          int32\n",
      "age             int32\n",
      "Credit_Score    int32\n",
      "dtir1           int32\n",
      "loan_amount     int32\n",
      "Status          int32\n",
      "dtype: object\n",
      "\n",
      "DataFrame head preview...\n",
      "    income  age  Credit_Score  dtir1  loan_amount  Status\n",
      "0    1740   34           758     45       116500       1\n",
      "2    9480   44           834     46       406500       0\n",
      "3   11880   54           587     42       456500       0\n",
      "\n",
      "DataFrame tail preview...\n",
      "         income  age  Credit_Score  dtir1  loan_amount  Status\n",
      "148667    6900   54           702     49       446500       0\n",
      "148668    7140   64           737     29       196500       0\n",
      "148669    7260   54           830     44       406500       0\n",
      "\n",
      "DataFrame description...\n",
      "           income        age  Credit_Score      dtir1  loan_amount     Status\n",
      "count  124439.00  124439.00     124439.00  124439.00    124439.00  124439.00\n",
      "mean     7013.19      54.85        699.80      37.74    328865.90       0.16\n",
      "std      6508.56      13.26        115.83      10.54    182287.52       0.37\n",
      "min         0.00      25.00        500.00       5.00     16500.00       0.00\n",
      "25%      3780.00      44.00        600.00      31.00    196500.00       0.00\n",
      "50%      5760.00      54.00        699.00      39.00    296500.00       0.00\n",
      "75%      8580.00      64.00        800.00      45.00    436500.00       0.00\n",
      "max    578580.00      74.00        900.00      61.00   3576500.00       1.00\n"
     ]
    }
   ],
   "source": [
    "# DataFrame after preprocessing\n",
    "\n",
    "print(\"\\nData types post processing...\\n\",df.dtypes)\n",
    "print(\"\\nDataFrame head preview...\\n\",df.head(3))\n",
    "print(\"\\nDataFrame tail preview...\\n\",df.tail(3))\n",
    "print(\"\\nDataFrame description...\\n\",df.describe().round(2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The outcome of the preprocessing can be viewed in the above cell's output. All columns are now an integer data type, the DataFrame head preview shows the data is formatted, and the DataFrame description is able to now give meaningful analysis for the dataset. However, there is one item of concern. The min values for income and age are 0 which signifies incomplete data for those rows in the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame description...\n",
      "           income        age  Credit_Score      dtir1  loan_amount     Status\n",
      "count  124091.00  124091.00     124091.00  124091.00    124091.00  124091.00\n",
      "mean     7032.86      54.85        699.80      37.81    328905.25       0.16\n",
      "std      6507.06      13.26        115.83      10.47    182183.98       0.37\n",
      "min        60.00      25.00        500.00       5.00     16500.00       0.00\n",
      "25%      3780.00      44.00        600.00      31.00    196500.00       0.00\n",
      "50%      5820.00      54.00        699.00      39.00    296500.00       0.00\n",
      "75%      8580.00      64.00        800.00      45.00    436500.00       0.00\n",
      "max    578580.00      74.00        900.00      61.00   3576500.00       1.00\n",
      "\n",
      "\n",
      "DataFrame WITH NaN values row count...\n",
      " 124439\n",
      "\n",
      "DataFrame WITHOUT NaN values row count...\n",
      " 124091\n"
     ]
    }
   ],
   "source": [
    "# set columns to replace 0 values to NaN, then have the NaN values removed\n",
    "\n",
    "df['age'] = df['age'].replace(0, np.nan)\n",
    "df['income'] = df['income'].replace(0, np.nan)\n",
    "\n",
    "# remove NaN values from the DataFrame\n",
    "df = df.dropna()\n",
    "\n",
    "# DataFrame statistics after removing NaN values\n",
    "print(\"\\nDataFrame description...\\n\",df.describe().round(2))\n",
    "\n",
    "\n",
    "print(\"\\n\\nDataFrame WITH NaN values row count...\\n\", len(df_with_nan))\n",
    "print(\"\\nDataFrame WITHOUT NaN values row count...\\n\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With the 0 values removed, the dataset description shows a more meaningful statistical overview. \n",
    "* It can be confirmed by the before and after DataFrame len() change. 10,410 rows contained 0 or NaN which were dropped from the DataFrame.\n",
    "\n",
    "### 2. Splitting training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the dataset for training\n",
    "X = df[['income', 'age', 'Credit_Score', 'dtir1', 'loan_amount']].values\n",
    "y = df['Status'].values  # Assuming the target variable column is 'Status'\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scaling and cost computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "vc = VotingClassifier(estimators=[('rf', rf), ('gb', gb)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold models and their names\n",
    "models = {'Random Forest': rf, 'Gradient Boosting': gb, 'Voting Classifier': vc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1, 'ROC-AUC': roc_auc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model: Random Forest\n",
      "\n",
      "**Performance metrics**\n",
      "Accuracy: 0.8433\n",
      "Precision: 0.5604\n",
      "Recall: 0.1423\n",
      "F1 Score: 0.2269\n",
      "ROC-AUC: 0.6662\n"
     ]
    }
   ],
   "source": [
    "# Compare models\n",
    "best_model = max(results, key=lambda k: results[k]['F1 Score'])\n",
    "print(f\"Best performing model: {best_model}\\n\")\n",
    "print(\"**Performance metrics**\")\n",
    "for metric, value in results[best_model].items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Insights:\n",
      "The **Random Forest** model\n",
      "performed best in terms of F1 Score,\n",
      "indicating a balanced performance between precision and recall.\n",
      "This model might be well-suited for credit risk assessment in fintech\n",
      "as it effectively balances the trade-off between identifying potential\n",
      "defaults (recall) and minimizing false alarms (precision), crucial for\n",
      "making informed loan approval decisions.\n"
     ]
    }
   ],
   "source": [
    "# Insights\n",
    "print(\"\\nInsights:\")\n",
    "print(\n",
    "    f\"The **{best_model}** model\\n\"\n",
    "    f\"performed best in terms of F1 Score,\\n\"\n",
    "    f\"indicating a balanced performance between precision and recall.\\n\"\n",
    "    f\"This model might be well-suited for credit risk assessment in fintech\\n\"\n",
    "    f\"as it effectively balances the trade-off between identifying potential\\n\"\n",
    "    f\"defaults (recall) and minimizing false alarms (precision), crucial for\\n\"\n",
    "    f\"making informed loan approval decisions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
